{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve, parse and combine db information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zotero database\n",
    "zotero_csv = pd.read_csv('zotero.csv')  # library exported as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zotero RDF\n",
    "Use Zotero RDF export to get information about which items are in which collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zotero rdf databse\n",
    "# it will be used to get information about collections\n",
    "tree = ET.parse('zotero.rdf')  # library exported as rdf\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdf's 'about' to zotero's 'key' mapping\n",
    "keys = {}\n",
    "tags = []\n",
    "for child in root:\n",
    "    key = child.find('{http://www.zotero.org/namespaces/export#}key')\n",
    "    if key is not None:\n",
    "        # if it has a zotero key, push it to the items array\n",
    "        about = child.get('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}about')\n",
    "        if child.tag != '{http://www.zotero.org/namespaces/export#}Attachment':\n",
    "            # exclude attachments because they have no relevant data\n",
    "            # and are not included in the csv\n",
    "            keys[about] = key.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = {}\n",
    "for collection in root.iter('{http://www.zotero.org/namespaces/export#}Collection'):\n",
    "    title = collection.find('{http://purl.org/dc/elements/1.1/}title').text\n",
    "    collection_id = collection.get('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}about')\n",
    "    children = []\n",
    "    subcollections = []\n",
    "    for child in collection.findall('{http://purl.org/dc/terms/}hasPart'):\n",
    "        resource = child.get('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}resource')\n",
    "        if resource.startswith('#collection_'):\n",
    "            subcollections.append(resource)\n",
    "        else:\n",
    "            children.append(resource)\n",
    "    collections[collection_id] = {\n",
    "        'title': title,\n",
    "        'subcollections': set(subcollections),\n",
    "        'children': set(children)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get immediate parent for each collection\n",
    "collection_parents = {}\n",
    "for collection_id, collection in collections.items():\n",
    "    for subcollection in collection['subcollections']:\n",
    "        collection_parents[subcollection] = collection_id\n",
    "    if collection_id not in collection_parents:\n",
    "        collection_parents[collection_id] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get full ancestry for each collection (i.e., parent, grandparent, etc)\n",
    "collection_ancestries = {}\n",
    "for collection in collection_parents.keys():\n",
    "    collection_id = collection\n",
    "    ancestry = []\n",
    "    while True:\n",
    "        parent = collection_parents[collection_id]\n",
    "        if parent is not None:\n",
    "            ancestry.insert(0, parent)\n",
    "            collection_id = parent\n",
    "        else:\n",
    "            break\n",
    "    collection_ancestries[collection] = ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fullname for each collection: '... > grandparent > parent > child'\n",
    "collection_fullnames = {}\n",
    "for collection_id, collection in collections.items():\n",
    "    name = collection['title']\n",
    "    ancestor_names = [collections[ancestor]['title'] for ancestor in collection_ancestries[collection_id]]\n",
    "    fullname = ancestor_names.append(name)\n",
    "    collection_fullnames[collection_id] = ' > '.join(ancestor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list collections per item\n",
    "item_collections = {}\n",
    "for collection_id, collection in collections.items():\n",
    "    collection_fullname = collection_fullnames[collection_id]\n",
    "    for child in collection['children']:\n",
    "        if child in keys:\n",
    "            # ignore references to items not in the keys dict\n",
    "            key = keys[child]\n",
    "            if key not in item_collections:\n",
    "                item_collections[key] = []\n",
    "            item_collections[key].append(collection_fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_df = pd.DataFrame([{'Key': about, 'collections': collections} for about, collections in item_collections.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine data\n",
    "Merge information about sources coming from the csv export file with information about collections coming from the rdf export file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zotero_df = zotero_csv.merge(collections_df, how='outer', on='Key')\n",
    "\n",
    "# if item belongs to no collection, replace nan with empty array\n",
    "zotero_df.collections = zotero_df.collections.apply(lambda x: [] if x is np.nan else x)\n",
    "\n",
    "# converge collections into their root collections\n",
    "# for example: a > b > c --> a\n",
    "def only_root_collections(collections):\n",
    "    root_collections = []\n",
    "    for collection in collections:\n",
    "        root_collection = collection.split(' > ')[0]\n",
    "        root_collections.append(root_collection)\n",
    "    return list(set(root_collections))\n",
    "\n",
    "zotero_df['root_collections'] = zotero_df['collections'].apply(only_root_collections)\n",
    "\n",
    "# return unique root collections\n",
    "root_collections = list(set(zotero_df.root_collections.sum()))\n",
    "\n",
    "# add one column per root collection, and show true/false if item belongs to it\n",
    "for root_collection in root_collections:\n",
    "    zotero_df['RC: ' + root_collection] = zotero_df.root_collections.apply(lambda x: root_collection in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What type of sources are there in the database?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different types of sources (journal articles, books, book sections, etc). As long as the author name is available, estimating the gender is relatively straightforward regardless of the source type.  \n",
    "However, depending on the type of source, how to determine the contact information and the author's location might change.  \n",
    "Therefore, a first step would be to find out what is the proportion of each source type in the database. Note that the database has different collections, so a general view and a per-collection view will be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_collections = [column for column in zotero_df.columns if column.startswith('RC: ')]\n",
    "\n",
    "df = zotero_df.loc[:, ['Key', 'Item Type', 'collections'] + root_collections]\n",
    "\n",
    "# add 'any' root collection for plotting\n",
    "df['any'] = True\n",
    "root_collections.insert(0, 'any')\n",
    "\n",
    "# transform wide array into long array\n",
    "df2 = pd.DataFrame()\n",
    "for root_collection in root_collections:\n",
    "    tmp = df.loc[df[root_collection], ['Key', 'Item Type']]\n",
    "    tmp['root_collection'] = root_collection\n",
    "    df2 = pd.concat([df2, tmp])\n",
    "\n",
    "df2 = df2.reset_index(drop=True)\n",
    "\n",
    "# plot\n",
    "df3 = df2.groupby(['root_collection', 'Item Type']).agg({'Key': 'count'}).reset_index()\n",
    "df3 = df3.rename(columns={'Key': 'count'})\n",
    "\n",
    "# sorted item_types\n",
    "item_types = df3.groupby('Item Type')['count'].sum().sort_values(ascending=False).index\n",
    "\n",
    "sns.catplot(\n",
    "    x='root_collection',\n",
    "    y='count',\n",
    "    hue='Item Type',\n",
    "    data=df3,\n",
    "    order=root_collections,\n",
    "    hue_order=item_types,\n",
    "    kind='bar'\n",
    ")\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()\n",
    "\n",
    "del df, df2, df3, root_collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author information\n",
    "### Make an author database\n",
    "Gender and procedence are author information.\n",
    "\n",
    "Therefore, it will be useful to expand the sources database (one row per source) into an author database (one row per author per source).\n",
    "\n",
    "Some sources have 'Authors' (e.g., journal articles). Others have 'Editors' too (e.g., books with multiple authors). There may be other \"person\" categories. These will be obtained from the rdf export file. Note that some of these categories in the RDF file seem to be collapsed into the \"Author\" category in the CSV file (e.g., Podcaster -> Author).\n",
    "\n",
    "- A 'Role' column will be added to the author database indicating whether the person is an author, editor, etc, for the corresponding source.\n",
    "- A 'Order' column will be added indicating whether an author/editor/etc is the 1st, 2nd, ... author/editor/etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types of agents (e.g., Author, Editor)\n",
    "agent_types = root.findall('.//{http://xmlns.com/foaf/0.1/}Person/../../..')\n",
    "agent_types = list(set([\n",
    "    element\n",
    "        .tag\n",
    "        .split('}')[-1]\n",
    "        .capitalize()[:-1]\n",
    "    for element in agent_types\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what columns in the original df correspond to agent/creators?\n",
    "agent_columns = [column for column in zotero_df.columns if column in agent_types]\n",
    "\n",
    "# expand the original df, one row per creator per source\n",
    "authors_df = pd.DataFrame()\n",
    "for agent_column in agent_columns:\n",
    "    df = zotero_df.loc[:, ['Key', agent_column]]\n",
    "    df[agent_column] = df[agent_column].str.split(';')\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "            .set_index('Key')[agent_column]\n",
    "            .apply(pd.Series)\n",
    "            .stack()\n",
    "            .reset_index()\n",
    "            .rename(columns={\n",
    "                'level_1': 'Creator Order',\n",
    "                0: 'Creator'\n",
    "            })\n",
    "    )\n",
    "    df['Creator Role'] = agent_column\n",
    "    authors_df = pd.concat([authors_df, df])\n",
    "\n",
    "authors_df = authors_df.reset_index(drop=True)\n",
    "\n",
    "# bring information of complete df into the expanded df\n",
    "authors_df = authors_df.merge(\n",
    "    zotero_df[[column for column in zotero_df.columns if column not in agent_columns]],\n",
    "    how='outer',\n",
    "    on='Key',\n",
    ")\n",
    "authors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Worldwide gender-name dictionary to infer gender from name\n",
    "> Julio Raffo, 2016.  \n",
    "> \"Worldwide Gender-Name Dictionary,\" WIPO Economics & Statistics Related Resources\n",
    "> 10, World Intellectual Property Organization - Economics and Statistics Division.\n",
    "> <https://ideas.repec.org/c/wip/eccode/10.html>\n",
    "\n",
    "They have information from 14 different sources. Each source may have information from more than one country. Hence, the units of information are name-country pairs (and their reported gender).  \n",
    "They report that there is 10% overlap between sources (i.e., names provided by more than one source), but that only in some cases (0.7%) there are conflicts between sources (i.e., name-country pairs which are reported with different genders among sources).\n",
    "\n",
    "This source provides four different databases:\n",
    "- WGND_source: this is the original data. A list of name-country pairs, and the gender reported by each of the 14 information sources.\n",
    "- WGND_country: a list of name-country pairs, with the consensus gender among sources (given that the rate of conflict is low).\n",
    "- WGND_noctry: including only names without conflict among countries (hence, the shortest database).\n",
    "- WGND_langctry: an expanded database, where each name-country pair was expanded to include other countries which speak the same language.\n",
    "For more information, see the original paper: https://www.wipo.int/edocs/pubdocs/en/wipo_pub_econstat_wp_33.pdf\n",
    "\n",
    "We will use the WGND_country database here.\n",
    "...\n",
    "\n",
    "Working with the CSV export from Zotero, agents (authors, editors, etc) are separated with ';', and are displayed in the form  \"\\<surname\\>, \\<givenName\\>\".  \n",
    "It will be assumed that if no comma is present, the agent is not a person but an institution instead, and gender will not be inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Worldwide gender-name dictionary\n",
    "# only empty string '' will be taken as 'nan',\n",
    "# otherwise 'na' is taken as 'nan' (and there are names and codes 'na' in the db)\n",
    "names = pd.read_csv('wgnd_ctry.csv', na_values=[''], keep_default_na=False)\n",
    "names.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender(fullname):\n",
    "    # given an author's fullname (surname, name), it returns:\n",
    "    # consensus gender: most frequent gender for the given names\n",
    "    # agreement index: percentage of agreement for the consensus gender\n",
    "    # split: if the name was found \"as-is\", or if it had to be split to be found\n",
    "    # male/female/ambiguous: details of the matches found\n",
    "    import unicodedata\n",
    "    import regex\n",
    "    result = {\n",
    "        'gender': None,\n",
    "        'agreement': None,\n",
    "        'split': None,\n",
    "        'male': None,\n",
    "        'female': None,\n",
    "        'ambiguous': None\n",
    "    }\n",
    "    \n",
    "    if fullname == fullname:  # false for nan\n",
    "        fullname = fullname.split(', ')\n",
    "\n",
    "        if len(fullname) == 2:\n",
    "            # keep given names only (do not use surname)\n",
    "            name_string = fullname[-1]\n",
    "            # drop accents\n",
    "            name_string = u\"\".join(\n",
    "                [c for c in unicodedata.normalize('NFKD', name_string) if not unicodedata.combining(c)]\n",
    "            )\n",
    "            # capitalize\n",
    "            name_string = name_string.upper()\n",
    "            # replace unicode dash-type characters (regex \\p{Pd}) with spaces\n",
    "            name_string = regex.sub(r'\\p{Pd}+', ' ', name_string)\n",
    "\n",
    "            # remove extra spaces at beginning and end\n",
    "            name_string = name_string.strip()\n",
    "            # find all matching name-country pairs\n",
    "            matching_names = names.loc[names['name'] == name_string, :]\n",
    "            if len(matching_names) > 0:\n",
    "                # the name was found \"as-is\"\n",
    "                did_split = False\n",
    "            else:\n",
    "                # the name was not found. Trying its parts separately\n",
    "                did_split = True\n",
    "                for name in name_string.split():\n",
    "                    # remove extra spaces at beginning and end\n",
    "                    name = name.strip()\n",
    "                    df = names.loc[names['name'] == name, :]\n",
    "                    matching_names = pd.concat([matching_names, df])\n",
    "\n",
    "            if len(matching_names) > 0:\n",
    "                result['split'] = did_split                \n",
    "\n",
    "                # get consensus gender and agreement index\n",
    "                # in case of match (equal counts) all most frequent genders are returned\n",
    "                # e.g., 'FM' if 'F' and 'M' are equally frequent\n",
    "                gender_counts = matching_names.gender.value_counts(normalize=True)\n",
    "                max_gender_freq = gender_counts.max()\n",
    "                result['gender'] = ''.join(\n",
    "                    gender_counts[gender_counts == max_gender_freq]\n",
    "                    .index\n",
    "                    .sort_values()\n",
    "                    .tolist()\n",
    "                )\n",
    "                result['agreement'] = max_gender_freq\n",
    "\n",
    "                # return details per gender\n",
    "                for key, gender in {'F': 'female', 'M': 'male', '?': 'ambiguous'}.items():\n",
    "                    result[gender] = matching_names[\n",
    "                        matching_names.gender == key\n",
    "                    ].groupby('name').code.apply(pd.Series.tolist).to_dict()\n",
    "            else:\n",
    "                result['gender'] = 'Name(s) not found'                \n",
    "        else:\n",
    "            result['gender'] = 'Unexpected name format'\n",
    "    else:\n",
    "        result['gender'] =  'No name'\n",
    "    \n",
    "    return pd.Series(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_path = 'gender.csv'\n",
    "if os.path.exists(gender_path):\n",
    "    gender_df = pd.read_csv(gender_path)\n",
    "else:\n",
    "    gender_df = authors_df.loc[:, 'Creator'].apply(get_gender)\n",
    "    gender_df = pd.concat([authors_df.loc[:, ['Key', 'Creator', 'Creator Role', 'Creator Order']], gender_df], axis=1)\n",
    "    gender_df.to_csv(gender_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output authors + gender database\n",
    "df = pd.concat([\n",
    "    authors_df,\n",
    "    gender_df.loc[:, [column for column in gender_df.columns if column not in ['Key', 'Creator', 'Creator Role', 'Creator Order']]]\n",
    "], axis=1)\n",
    "df.to_csv('authors.csv', index=False)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick gender plot\n",
    "collections_include = ['**CITED', '*WORK IN']\n",
    "\n",
    "df = pd.concat([authors_df, gender_df.loc[:, ['gender', 'agreement']]], axis=1)\n",
    "df['root_collections'] = df['collections'].apply(only_root_collections)\n",
    "df = df.loc[\n",
    "    (df['Creator Role'] == 'Author') &\n",
    "    (df['Creator Order'] == 0) &\n",
    "    (df['agreement'] > .75) &\n",
    "    (df['root_collections'].apply(lambda x: bool(set(x) & set(collections_include)))) & \n",
    "    True, \n",
    "    :\n",
    "]\n",
    "df = df.groupby('gender')['Key'].count()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible ambiguous bias from 'CA' name-country pairs?\n",
    "I was also noticing some ambiguous-gender bias coming from 'CA' name-country pairs. I.e., it looked as if in many cases all name-country pairs agreed on either 'male' or 'female', but the 'CA' pair disagreed with '?' (ambiguous). Hence, I'm plotting the name count per gender and code to see if 'CA' has a higher proportion of 'ambiguous' names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot name count per country and gender\n",
    "k = 5 # number of k codes to keep\n",
    "\n",
    "df = pd.crosstab(\n",
    "    names.code,\n",
    "    names.gender,\n",
    "    margins=True\n",
    "#     normalize='index'\n",
    ").reset_index()\n",
    "\n",
    "# exlude column margins\n",
    "df = df.loc[df.code != 'All', :]\n",
    "\n",
    "# sort by index margin (i.e., total name count per code)\n",
    "df = df.sort_values('All', ascending=False)\n",
    "\n",
    "# and then drop index margin\n",
    "df = df.loc[:, [column for column in df.columns if column != 'All']]\n",
    "\n",
    "# keep top k codes\n",
    "df = df[:k*3]\n",
    "\n",
    "# make wide df into long df\n",
    "df = df.melt(id_vars='code')\n",
    "\n",
    "sns.catplot(\n",
    "    x='code',\n",
    "    y='value',\n",
    "    hue='gender',\n",
    "    data=df,\n",
    "    kind='bar'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender - known issues\n",
    "- **Institution may be taken as people**: All authors with a format (*string*, *string*) are considered humans and looked up in the gender database. Even if they are institutions. For example, “Science, London School of Economics and Political”. A possible solution could be to use the RDF export file instead of the CSV, and use the “givenName” property (instead of looking for \"*string*, *string*\" and splitting at the *comma*).\n",
    "- **Some names are not found in WGND**: However, some of these name are found in other sources. For example, the name \"Laurajane\" is not found in WGND, but it is found in https://genderize.io/, or in https://genderapi.io/. A solution would be to look for these names in these services (they have APIs). In this case, build a list of names and genders retrieved, to minimize API calls. And add a column to the output indicating what source the gender was inferred with.\n",
    "- **Some sources have no authors declared**: Some of these cases could be solved when the Crossref API is called to get author affiliation information. This may also help with sources for which only the author's initial was included (these initials are not found in the gender database).\n",
    "- **Consensus gender may be biased in compund names**: Right now the consensus gender is calculated pooling all name-country pairs found in the database. This may bias the gender toward the name (in a multiple-part name) for which more entries were found. For example, if we are looking for “María José”, if there were more results for José than for María, then the consensus gender could be biased toward “José” (male). Alternatively, one consensus gender with its agreement index should be obtained for each name part, and only then averaged across names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem that 'CA' name-country pairs are heavily biased toward ambiguous gender. Hence, keeping this name-country pairs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
